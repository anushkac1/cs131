{"cells":[{"cell_type":"code","execution_count":55,"id":"83bfc2fe","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|PULocationID|DOLocationID|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["# import for spark \n","from pyspark.sql import SparkSession \n","\n","# need to start session for spark \n","spark = SparkSession.builder.appName(\"A4SparkSession\").getOrCreate()\n","\n","# read from csv file (uploaded in the dataproc cluster already)\n","df = spark.read.csv('gs://dataproc-staging-us-central1-20673574438-1npjkcso/2019-01-h1.csv', header=True, inferSchema=True)\n","\n","# reduce dataset to specified columns \n","small_dataset = df.select(\"passenger_count\",\"PULocationID\",\"DOLocationID\", \"total_amount\")\n","\n","# show first 10 entries of new dataset\n","small_dataset.show(10)\n","\n","#step 1 done"]},{"cell_type":"code","execution_count":56,"id":"14e62094","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 206:==========================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["train count: 2920849\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 209:==========================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["test count: 730150\n"]},{"name":"stderr","output_type":"stream","text":["\r\n","                                                                                \r"]}],"source":["# created train and test DF based on an 80/20 split and a seed of 42 (common w/data)\n","trainDF, testDF = small_dataset.randomSplit([0.8, 0.2], seed=42)\n","\n"," \n","#show number of rows in each df\n","print(\"train count:\", trainDF.count())\n","print(\"test count:\", testDF.count())\n","\n","#step 2 done"]},{"cell_type":"code","execution_count":57,"id":"f182217c","metadata":{},"outputs":[],"source":["# imports for decision tree (and combining columns into 1 vector)\n","from pyspark.ml.regression import DecisionTreeRegressor\n","from pyspark.ml.feature import VectorAssembler\n","\n","# combine three other features (case snesitive i think) into one column (vector)\n","assblr = VectorAssembler(\n","    inputCols=[\"passenger_count\", \"PULocationID\", \"DOLocationID\"],  \n","    outputCol=\"features\" \n",")\n","\n","# this is the decisin tree regressor \n","decTree = DecisionTreeRegressor(\n","    featuresCol=\"features\", \n","    labelCol=\"total_amount\" \n",")\n","\n","#step 3 done \n","\n","\n","\n","\n","\n","#need to be in same block due to varibales/imports from above needed for pipeline \n","#pipeline helps = simpler process\n","\n","#import for pipeline from pyspark \n","from pyspark.ml import Pipeline\n","\n","#make pipeline\n","pipeline = Pipeline(stages=[assblr, decTree])\n","\n","#step 4 done "]},{"cell_type":"code","execution_count":58,"id":"6a429f97","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 226:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------------+------------+\n","|passenger_count|PULocationID|DOLocationID|        prediction|total_amount|\n","+---------------+------------+------------+------------------+------------+\n","|            0.0|         4.0|         4.0|22.591374728615502|         4.3|\n","|            0.0|         4.0|        33.0|19.228018304431938|       17.75|\n","|            0.0|         4.0|        68.0|18.810800590405595|        15.8|\n","|            0.0|         4.0|        79.0|18.810800590405595|        9.75|\n","|            0.0|         4.0|       125.0|18.810800590405595|         9.3|\n","|            0.0|         4.0|       170.0|18.810800590405595|       11.15|\n","|            0.0|         7.0|         7.0|22.591374728615502|        0.31|\n","|            0.0|         7.0|         7.0|22.591374728615502|         6.3|\n","|            0.0|         7.0|       112.0|18.810800590405595|        16.8|\n","|            0.0|         7.0|       138.0|18.810800590405595|        10.8|\n","+---------------+------------+------------+------------------+------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r\n","                                                                                \r"]}],"source":["# set max bins for better accurate results (chose a high number = 80)\n","decTree.setMaxBins(80)\n","\n","# trained decision tree fitted pipeline stored in model (features combined and decision tree regressor used)\n","modelFitted = pipeline.fit(trainDF)\n","\n","# predict test data (try it out)\n","predicted = modelFitted.transform(testDF)\n","\n","# first five precited versus actual show - step 6 with first 10 values\n","predicted.select(\"passenger_count\",\"PULocationID\",\"DOLocationID\",\"prediction\",\"total_amount\").show(10)\n","\n","#step 5 & 6 done"]},{"cell_type":"code","execution_count":59,"id":"0ff09772","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 227:============================>                            (2 + 2) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["Root Mean Squared Error aka RMSE for this model is: 24.62693035407849\n"]},{"name":"stderr","output_type":"stream","text":["\r\n","[Stage 227:==========================================>              (3 + 1) / 4]\r\n","\r\n","                                                                                \r"]}],"source":["# need this ipmport to calculate RMSE value \n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# evaluate via regressionevaluater \n","evaluation = RegressionEvaluator(\n","# these are the actual numbers\n","labelCol=\"total_amount\",  \n","# this is what the model predicted\n","predictionCol=\"prediction\",  \n","# given actual vs predicted what is our RMSE (root mean squared error)\n","metricName=\"rmse\")\n","\n","# find RMSE score\n","rmseScore = evaluation.evaluate(predicted)\n","\n","# print RMSE score \n","print(f\"Root Mean Squared Error aka RMSE for this model is: {rmseScore}\")\n","\n","#step 7 done "]},{"cell_type":"code","execution_count":null,"id":"73346c74","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"1bfe0fca","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}
